# EER-Research-Project
A research project investigating a new machine learning procedure for optimal variable and model selection.
This proposed method is called Estimated Exhaustive Regression, it was originally proposed in a working paper by noted econometrician
Dr. Antony Davies, most well known for his invention of the first known framework for analyzing multi-dimensional panel data in his doctoral dissertation.
The aforementioned working paper is included in this repository in the pdf called "(draft version) An Exploration of Regression-Based Data Mining Techniques by Antony Davies (2008)."

This novel feature selection algorithm involves an adjustment on the All Subsets Regression aka Best Subset Selection procedure whereby only a random subset of j of all of the possible 2^k - 1 regression specifications evaluated by the traditional version of ASR, and evaluating which of them is best by a Relative Cross-Model Chi-Square Criterion as an alternative to any of the typical regression model performance metrics. This is used in order to better identify which optimal variables selected for inclusion in the final regression specification out of all candidate variables is only selected by the algorithm spuriously.

I am collaborating with Antony Davies on this updating of his original research (the results of which we intend to re-submit for publication in 2023) which
mostly involves the addition of two extra Benchmark Methods to compare EER's performance with, namely: LASSO Regression and Forward Selection Stepwise Regression. 
The original WP only compared EER to Backward Elimination Stepwise Regression and a different computationally feasible version of the Best Subset Selection which only selects regressor candidates from subests of equal size set by the analyst just like his EER procedure, but instead of evaluating which candidates to select via a relative cross-model chi-square critereon, it used k-hold cross-validation. Backward Elimination was kept as the 3rd major Benchmark.

Dr. Davies is running his EER Procedure on 260,000 randomly generated synthetic datasets using Stata, while I am running LASSO Regressions, Backward, and Forward Stepwise Regressions on the same set of 260k datasets using R and comparing the results of EER with them subsequently. The scripts I used to run these benchmark comparisons are called: BE and FS Stepwise Regressions.R, LASSO Regressions.R, LASSO using Lars.R, and LASSO using the 'glmnet' package.R. 

I ended up having to run 2 different attempted replications of my LASSO results in terms of which variables they selected and finding out that not only were neither of them the same as the first one (LASSO Regressions.R which fits each LASSO using an the enet() function from the elastic net package in R), neither were exactly the same as each other either before I decided to investigate further and found out that different fitting functions for LASSO in R from different packages actually pick the lambda value in different ways due to different underlying stopping procedures, so I kept the results of all three of these in! This means we have 5 benchmark comparison methods instead of just 3.

It is important for anyone interested in understanding the findings in this research as to how well his EER algorithm performed compared to the 3, 4, or 5 Benchmarks I ran depending on how you want to count them, to understand how the 260k datasets were created. They were created using the Macro Enabled Excel Workbook in this Repo called real data generator.xlsm. Each of the datasets has 503 rows by 31 columns. The first column contains the synthetic observations on the Dependant Variable called Y starting in the 4th row and going all the way down to the 503rd row for 500 random observations on Y in each dataset. Meanwhile, columns 2-31 all contain 500 random observations in the same rows on candidate regressors whose labels are similarly in the 3rd row, their labels are X1, X2, X3, ..., X28, X29, X30. The first row has a proper row label, cell A1 says Regressor, and from then on, cells B1:AE1 contain binary indicators as to whether that candidate regressor is actually included in what econometricians call the Structural Equation which accurately models the phenomenon or proceess the data is taken as describing. The second row is just a copy of the 

The 'top 50' folder contains the first 50 csv file formatted datasets and the 'last 50' folder contains the last 50 of the 260k. Each dataset name is of the general form n-N-N-N.csv. 
